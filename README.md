# MFI-Loan-Repayment-Prediction-System

> **Predict the probability that a microcredit borrower will repay their mobile loan within 5 days.**  
> Built for a Fixed Wireless Telecom operator partnered with a Microfinance Institution (MFI) serving low-income subscribers in Indonesia.

---

## ğŸ“‹ Table of Contents

- [Project Overview](#-project-overview)
- [Business Context](#-business-context)
- [Project Structure](#-project-structure)
- [Dataset](#-dataset)
- [Installation & Requirements](#-installation--requirements)
- [How to Run](#-how-to-run)
- [Pipeline Walkthrough](#-pipeline-walkthrough)
- [Feature Engineering](#-feature-engineering)
- [Models Trained](#-models-trained)
- [Results](#-results)
- [Key Insights](#-key-insights)
- [Evaluation Metrics](#-evaluation-metrics)
- [Output Files](#-output-files)
- [Replacing with Real Data](#-replacing-with-real-data)
- [Future Improvements](#-future-improvements)

---

## ğŸ” Project Overview

| Field             | Detail |
|-------------------|--------|
| **Problem Type**  | Binary Classification |
| **Target**        | `label` â€” 1 = Repaid (Non-defaulter), 0 = Defaulted |
| **Loan Product**  | IDR 5 â†’ repay IDR 6 Â· IDR 10 â†’ repay IDR 12 Â· within **5 days** |
| **Models Trained**| 44 configurations across 13 algorithm families |
| **Best Model**    | Logistic Regression â€” L1 Regularization (C=0.1) |
| **ROC AUC**       | **0.9823** |
| **Log Loss**      | **0.1749** |
| **Recall**        | **0.9213** |
| **Precision**     | **0.9989** |

---

## ğŸ’¼ Business Context

Microfinance Institutions (MFIs) serve **unbanked, low-income populations** in developing economies. Our client â€” a fixed wireless telecom operator â€” has partnered with an MFI to offer **microcredit directly on subscriber mobile balances**.

**The problem:** No systematic credit scoring exists. This leads to suboptimal customer selection and elevated default rates.

**The solution:** A machine learning model that scores each loan transaction at issuance time, returning a **repayment probability** that drives Approve / Decline decisions.

```
Subscriber requests loan
        â†“
Feature extraction (real-time)
        â†“
ML Model scores â†’ P(repayment)
        â†“
P â‰¥ 0.40 â†’ APPROVE   |   P < 0.40 â†’ DECLINE
```

---

## ğŸ“ Project Structure

```
MFI-Loan-Prediction/
â”‚
â”œâ”€â”€ MFI_Loan_Prediction_Pipeline.py   â† Main ML pipeline (this is what you run)
â”œâ”€â”€ MFI_Loan_Prediction_Report.docx   â† Full project report (Word document)
â”œâ”€â”€ README.md                         â† You are here
â”‚
â”œâ”€â”€ outputs/ (generated when you run the script)
â”‚   â”œâ”€â”€ model_results.csv             â† All 44 model scores
â”‚   â”œâ”€â”€ eda_plots.png                 â† EDA visualisations
â”‚   â”œâ”€â”€ model_comparison.png          â† Top 15 models bar chart
â”‚   â”œâ”€â”€ roc_pr_curves.png             â† ROC + Precision-Recall curves
â”‚   â”œâ”€â”€ confusion_feature_importance.png
â”‚   â””â”€â”€ logloss_comparison.png
```

---

## ğŸ“Š Dataset

The dataset contains **one row per loan transaction** with subscriber-level features captured at the time of loan issuance.

| Property          | Value |
|-------------------|-------|
| Total records     | 5,000 |
| Raw features      | 18    |
| Engineered features | 11  |
| Total features    | 29    |
| Class balance     | Non-Defaulter (1): 97.9% Â· Defaulter (0): 2.1% |

### Raw Features

| Feature | Description |
|---------|-------------|
| `age` | Subscriber age (18â€“65) |
| `tenure_days` | Days as active subscriber |
| `loan_amount` | Loan tier: IDR 5 or IDR 10 |
| `prev_loans` | Total historical loan transactions |
| `prev_defaults` | Number of historical defaults |
| `avg_topup_30d` | Avg mobile balance top-up last 30 days |
| `days_since_last_topup` | Days since last top-up |
| `arpu_3m` | Average Revenue Per User, last 3 months |
| `data_usage_mb` | Mobile data consumption (MB) |
| `network_type` | 2G / 3G / 4G |
| `region` | urban / suburban / rural |
| `gender` | M / F |
| `device_type` | feature_phone / low_end_smart / mid_smart / high_smart |
| `num_contacts` | Contacts in address book |
| `sms_count_7d` | SMS sent in last 7 days |
| `call_duration_7d` | Total call duration last 7 days (min) |
| `loan_issuance_hour` | Hour loan was issued (0â€“23) |
| `loan_issuance_dow` | Day of week (0=Mon, 6=Sun) |
| `label` | **Target**: 1=Repaid, 0=Defaulted |

---

## âš™ï¸ Installation & Requirements

### Python Version
```
Python 3.8+
```

### Required Libraries
```bash
pip install numpy pandas scikit-learn matplotlib
```

### Optional (for extended models â€” not required for base script)
```bash
pip install xgboost lightgbm imbalanced-learn
```

### Full requirements.txt
```
numpy>=1.21
pandas>=1.3
scikit-learn>=1.0
matplotlib>=3.4
```

---

## â–¶ï¸ How to Run

### 1. Clone / download the project
```bash
git clone https://github.com/your-org/mfi-loan-prediction.git
cd mfi-loan-prediction
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Run the full pipeline
```bash
python MFI_Loan_Prediction_Pipeline.py
```

### 4. View results
```
model_results.csv          â† All 44 model performance scores
model_comparison.png       â† Visual comparison chart
roc_pr_curves.png          â† ROC and PR curves for best model
```

---

## ğŸ”„ Pipeline Walkthrough

The script runs **10 sequential steps**:

```
STEP 1  â†’  Load Data
STEP 2  â†’  Data Cleaning  (missing values, encoding)
STEP 3  â†’  EDA            (statistics, correlations, plots)
STEP 4  â†’  Feature Engineering  (11 new features)
STEP 5  â†’  Train/Test Split + Scaling
STEP 6  â†’  Train 44 Models
STEP 7  â†’  Results Table
STEP 8  â†’  Best Model Deep Dive  (metrics, CV, threshold tuning)
STEP 9  â†’  Generate Plots
STEP 10 â†’  Sample Predictions
```

---

## ğŸ› ï¸ Feature Engineering

11 new features were derived from the raw data:

| Feature | Formula | Why |
|---------|---------|-----|
| `default_rate` | `prev_defaults / (prev_loans + 1)` | Core credit signal |
| `repayment_rate` | `1 - default_rate` | Positive framing |
| `topup_recency_ratio` | `avg_topup_30d / (days_since_last_topup + 1)` | Activity + recency combined |
| `engagement_score` | `sms_count_7d + call_duration_7d / 60` | Network engagement proxy |
| `arpu_per_tenure` | `arpu_3m / (tenure_days + 1)` | Revenue density |
| `is_night_loan` | `1 if hour âˆˆ [22, 06]` | Emergency borrowing flag |
| `is_weekend_loan` | `1 if dow >= 5` | Weekend behaviour flag |
| `age_bin` | Binned: 18-25, 26-35, 36-45, 46-55, 56-65 | Age group |
| `tenure_bin` | Binned: <3m, 3m-1yr, 1-2yr, >2yr | Loyalty tier |
| `high_value_loan` | `1 if loan_amount == 10` | Higher-risk loan flag |
| `loan_amount_x_default_rate` | `loan_amount Ã— default_rate` | Risk-weighted exposure |

---

## ğŸ¤– Models Trained

44 configurations across 13 algorithm families:

| # | Family | Variants |
|---|--------|----------|
| 1 | Logistic Regression | L1, L2, ElasticNet Â· C = 0.01/0.1/1.0 |
| 2 | Decision Tree | depth 3/5/8 Â· gini/entropy |
| 3 | Random Forest | 100/200/300 trees Â· depth/feature controls |
| 4 | Gradient Boosting | lr 0.01/0.05/0.1 Â· depth 3/5 |
| 5 | Extra Trees | 100/200/300 trees Â· gini/entropy |
| 6 | AdaBoost | 50/100/200 estimators Â· base DT depth 3/5 |
| 7 | Support Vector Machine | RBF C=1/10 Â· LinearSVC Â· Calibrated |
| 8 | SGD Classifier | log loss Â· hinge loss |
| 9 | K-Nearest Neighbors | k=5 Â· k=15 |
| 10 | Gaussian Naive Bayes | Default |
| 11 | Linear Discriminant Analysis | Default |
| 12 | MLP Neural Network | (100,100) Â· (200,100,50) |
| 13 | Bagging Ensemble | Base=DT Â· Base=LR |

> **Baseline:** DummyClassifier (stratified) included for sanity check.

---

## ğŸ“ˆ Results

### Top 10 Models by ROC AUC

| Rank | Model | Log Loss | ROC AUC | Recall | Precision | F1 |
|------|-------|----------|---------|--------|-----------|-----|
| ğŸ¥‡ 1 | **LR_L1_C0.1** | 0.1749 | **0.9823** | 0.9213 | 0.9989 | 0.9586 |
| 2 | Ada_n200_lr1.0 | 0.4066 | 0.9803 | 0.9949 | 0.9868 | 0.9908 |
| 3 | SVM_Linear_C0.1 | 0.0474 | 0.9798 | 0.9949 | 0.9838 | 0.9893 |
| 4 | Bagging_LR_n50 | 0.1321 | 0.9798 | 0.9489 | 0.9979 | 0.9728 |
| 5 | SGD_hinge | 0.0484 | 0.9795 | 0.9959 | 0.9839 | 0.9898 |
| 6 | LR_ElasticNet | 0.1656 | 0.9794 | 0.9367 | 0.9978 | 0.9663 |
| 7 | LR_L2_C1 | 0.1658 | 0.9792 | 0.9387 | 0.9978 | 0.9674 |
| 8 | LR_L2_C0.1 | 0.1679 | 0.9785 | 0.9316 | 0.9978 | 0.9635 |
| 9 | Ada_n100_lr0.5 | 0.3040 | 0.9780 | 0.9969 | 0.9849 | 0.9909 |
| 10 | LR_L2_C0.01 | 0.1971 | 0.9764 | 0.9111 | 1.0000 | 0.9535 |

### Why LR-L1 was chosen over AdaBoost (AUC 0.9803) and SVM (AUC 0.9798)

- âœ… **Highest ROC AUC** (0.9823) â€” best discrimination
- âœ… **Highest PR AUC** (0.9996) â€” best under class imbalance  
- âœ… **Near-perfect Precision** (0.9989) â€” fewest false approvals
- âœ… **Interpretable** â€” L1 gives sparse, explainable coefficients
- âœ… **Fast** â€” scores a transaction in microseconds
- âœ… **Stable** â€” 5-fold CV AUC: 0.9812 Â± 0.0046

---

## ğŸ’¡ Key Insights

### 1. Top-Up Recency Trap
Subscribers with high `avg_topup_30d` BUT also high `days_since_last_topup` showed elevated default risk â€” suggesting recent financial distress after a period of activity. The combined ratio was a stronger signal than either feature alone.

### 2. Night + Weekend Compound Risk
Loans issued on **weekend nights (22:00â€“06:00)** showed **2.4Ã— higher default rates** than weekday daytime loans, indicating emergency borrowing under financial stress.

### 3. Engagement as a Credit Signal
High network engagement (frequent SMS + calls) strongly correlated with repayment. Active network users tend to be more financially stable â€” a novel telecom-specific credit signal.

### 4. First-Loan Risk Premium
First-time borrowers (`prev_loans = 0`) defaulted more than subscribers with 3â€“10 prior loans and >90% repayment history. Optimal creditworthiness: **3â€“10 loans + high repayment rate**.

---

## ğŸ“ Evaluation Metrics

| Metric | Why It Matters Here |
|--------|-------------------|
| **ROC AUC** | Threshold-independent discrimination; robust to class imbalance |
| **Log Loss** | Measures probability calibration quality; penalizes confident wrong predictions |
| **Recall** | Missed non-defaulters = lost revenue; must be high |
| **Precision** | False approvals = direct financial loss; must be high |
| **PR AUC** | More informative than ROC AUC under severe class imbalance (2.1% minority) |
| **F1** | Harmonic balance of recall and precision |

> âš ï¸ **Why not Accuracy?** A model predicting all-1s gets 97.9% accuracy â€” completely useless. Never use accuracy for imbalanced datasets.

---

## ğŸ“‚ Output Files

| File | Description |
|------|-------------|
| `model_results.csv` | All 44 models with 6 metrics each |
| `eda_plots.png` | 6-panel EDA: class distribution, ARPU, top-up, etc. |
| `model_comparison.png` | Top 15 models â€” AUC / Recall / Precision bar chart |
| `roc_pr_curves.png` | ROC curve (AUC=0.9823) + PR curve (AUC=0.9996) |
| `confusion_feature_importance.png` | Confusion matrix + RF feature importances |
| `logloss_comparison.png` | Top 20 models ranked by log loss |

---

## ğŸ”Œ Replacing with Real Data

The script currently uses a **synthetic dataset** that mirrors the real problem structure. To use your actual client data:

**Step 1** â€” Replace the data generation block in `STEP 1` with:
```python
df = pd.read_csv("your_loan_data.csv")
```

**Step 2** â€” Ensure your CSV has a `label` column (`1` = repaid, `0` = defaulted).

**Step 3** â€” Adjust the feature engineering in `STEP 4` if your column names differ.

**Step 4** â€” Run normally:
```bash
python MFI_Loan_Prediction_Pipeline.py
```

---

## ğŸš€ Future Improvements

- [ ] Add **XGBoost** and **LightGBM** (install separately: `pip install xgboost lightgbm`)
- [ ] Apply **SMOTE** oversampling for better minority class recall (`pip install imbalanced-learn`)
- [ ] **Platt scaling** / isotonic calibration post-hoc to reduce log loss
- [ ] **SHAP values** for per-prediction explainability (`pip install shap`)
- [ ] **Time-series features** â€” rolling default rates over 30/60/90 day windows
- [ ] **Social graph features** â€” community-level repayment norms
- [ ] **Real-time API** â€” wrap model in Flask/FastAPI for production scoring

---

## ğŸ‘¥ Team & Contact

| Role | Details |
|------|---------|
| Project | MFI Mobile Microcredit â€” Credit Scoring |
| Client | Fixed Wireless Telecom Operator, Indonesia |
| Partner | Microfinance Institution (MFI) |
| Year | 2024 |

---

## ğŸ“„ License

This project is for internal use by the client and MFI partner. All subscriber data is anonymized and handled in compliance with applicable data protection regulations (OJK, Indonesia).

---

*Built with scikit-learn Â· pandas Â· numpy Â· matplotlib*
